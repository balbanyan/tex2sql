#!/usr/bin/env python3
"""
Simple OpenAI API test script with custom base URL and SSL verification disabled
"""

import openai
import httpx
import os
from typing import Optional

def test_openai_api(
    api_key: str,
    base_url: str,
    model: str = "gpt-3.5-turbo",
    message: str = "Hello! Can you respond with a simple greeting?"
) -> None:
    """
    Test OpenAI API with custom configuration
    
    Args:
        api_key: Your OpenAI API key
        base_url: Custom base URL for the API
        model: Model name to use
        message: Test message to send
    """
    
    try:
        # Create OpenAI client with custom configuration
        print(base_url)
        client = openai.OpenAI(
            base_url=base_url,
            api_key=api_key,
            http_client=httpx.Client(verify=False)
        )
        
        print("üöÄ Testing OpenAI API connection...")
        print(f"üì° Base URL: {base_url}")
        print(f"ü§ñ Model: {model}")
        print(f"üí¨ Message: {message}")
        print("-" * 50)
        
        # Make a simple chat completion request
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user", 
                    "content": message
                }
            ],
            max_tokens=150,
            temperature=0.7
        )
        
        # Print the response
        print("‚úÖ API Response received!")
        print(f"üìù Response: {response.choices[0].message.content}")
        print(f"üîß Model used: {response.model}")
        print(f"üéØ Tokens used: {response.usage.total_tokens}")
        
    except Exception as e:
        print(f"‚ùå Error occurred: {str(e)}")
        print(f"üîç Error type: {type(e).__name__}")

def test_streaming_api(
    api_key: str,
    base_url: str,
    model: str = "gpt-3.5-turbo",
    message: str = "Write a short poem about coding"
) -> None:
    """
    Test streaming API response
    """
    
    try:
        client = openai.OpenAI(
            #base_url=base_url,
            api_key=api_key,
            http_client=httpx.Client(verify=False)
        )
        
        print("\nüåä Testing Streaming API...")
        print(f"üí¨ Message: {message}")
        print("-" * 50)
        print("üìù Streaming response:")
        
        # Create streaming request
        stream = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": message
                }
            ],
            max_tokens=200,
            temperature=0.7,
            stream=True
        )
        
        # Print streaming response
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                print(chunk.choices[0].delta.content, end="", flush=True)
        
        print("\n‚úÖ Streaming completed!")
        
    except Exception as e:
        print(f"‚ùå Streaming error: {str(e)}")

def test_models_list(api_key: str, base_url: str) -> None:
    """
    Test listing available models
    """
    
    try:
        client = openai.OpenAI(
            #base_url=base_url,
            api_key=api_key,
            http_client=httpx.Client(verify=False)
        )
        
        print("\nüìã Testing Models List API...")
        print("-" * 50)
        
        # List available models
        models = client.models.list()
        
        print("‚úÖ Available models:")
        for model in models.data[:5]:  # Show first 5 models
            print(f"  ü§ñ {model.id}")
        
        if len(models.data) > 5:
            print(f"  ... and {len(models.data) - 5} more models")
            
    except Exception as e:
        print(f"‚ùå Models list error: {str(e)}")

def main():
    """
    Main function to run API tests
    """
    
    # Configuration - Update these values
    API_KEY = ""  # Replace with your actual API key
    BASE_URL = "https://api.openai.com/v1"  # Replace with your custom base URL
    MODEL = "gpt-3.5-turbo"  # Replace with your preferred model
    
    # You can also use environment variables
    API_KEY = os.getenv("OPENAI_API_KEY", API_KEY)
    BASE_URL = os.getenv("OPENAI_BASE_URL", BASE_URL)
    MODEL = os.getenv("OPENAI_MODEL", MODEL)
    
    # Validate configuration
    if API_KEY == "your-api-key-here" or not API_KEY:
        print("‚ùå Error: Please set your API key!")
        print("üí° Set OPENAI_API_KEY environment variable or update the script")
        return
    
    print("üß™ OpenAI API Test Script")
    print("=" * 50)
    
    # Test basic chat completion
    test_openai_api(
        api_key=API_KEY,
        base_url=BASE_URL,
        model=MODEL,
        message="Hello! Please respond with a simple greeting."
    )
    
    # Test streaming
    test_streaming_api(
        api_key=API_KEY,
        base_url=BASE_URL,
        model=MODEL,
        message="Write a haiku about programming"
    )
    
    # Test models list
    test_models_list(
        api_key=API_KEY,
        base_url=BASE_URL
    )
    
    print("\nüéâ All tests completed!")

if __name__ == "__main__":
    main()